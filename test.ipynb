{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "from MIL_layers import *\n",
    "import sklearn.metrics as metrics\n",
    "from VarMIL import *\n",
    "from CLAM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from timm.data import resolve_data_config\n",
    "# from timm.data.transforms_factory import create_transform\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login(token = \"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\")  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
    "\n",
    "# # pretrained=True needed to load UNI weights (and download weights for the first time)\n",
    "# # init_values need to be passed in to successfully load LayerScale parameters (e.g. - block.0.ls1.gamma)\n",
    "# model = timm.create_model(\"hf-hub:MahmoodLab/UNI\", pretrained=True, init_values=1e-5, dynamic_img_size=True)\n",
    "# transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# image = Image.open(\"UNI/.github/uni.jpg\")\n",
    "# image = transform(image).unsqueeze(dim=0) # Image (torch.Tensor) with shape [1, 3, 224, 224] following image resizing and normalization (ImageNet parameters)\n",
    "# with torch.inference_mode():\n",
    "#     feature_emb = model(image) # Extracted features (torch.Tensor) with shape [1,1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/train_dict.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "file_path = \"./data/test_dict.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    test_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dict['embeddings'][:,1:,:]\n",
    "y_train = train_dict['labels']\n",
    "X_test = test_dict['embeddings'][:,1:,:]\n",
    "y_test = test_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                               torch.tensor(y_train, dtype=torch.int))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), \n",
    "                              torch.tensor(y_test, dtype=torch.int))\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 1  # Adjust batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,lr=0.001,weight_decay=0.0005):\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) #betas ?\n",
    "\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        bag_label = label[0]\n",
    "        if torch.cuda.is_available():\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        \n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # calculate loss and metrics\n",
    "        loss, _ = model.calculate_objective(data, bag_label)\n",
    "        train_loss += loss.item()\n",
    "        error, _ = model.calculate_classification_error(data, bag_label)\n",
    "        train_error += error\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # step\n",
    "        optimizer.step()\n",
    "    \n",
    "    # calculate loss and error for epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "\n",
    "    print('Epoch: {}, Loss: {:.4f}, Train error: {:.4f}'.format(epoch, train_loss, train_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_error = 0.\n",
    "    y_pred =[]\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            bag_label = label[0]\n",
    "            if torch.cuda.is_available():\n",
    "                data, bag_label = data.cuda(), bag_label.cuda()\n",
    "            loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "            test_loss += loss.item()\n",
    "            error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "            test_error += error\n",
    "            y_pred.append(predicted_label.cpu().numpy().item())\n",
    "\n",
    "            #print('Predicted label: {}, True label: {}'.format(predicted_label.item(), bag_label))\n",
    "    test_error /= len(test_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('\\nTest Set, Loss: {:.4f}, Test error: {:.4f}'.format(test_loss, test_error))\n",
    "    print('Accuracy :' , accuracy_score(y_test, y_pred))\n",
    "    print('Precision :' , precision_score(y_test, y_pred))\n",
    "    print('Recall :' , recall_score(y_test, y_pred))\n",
    "    print('F1 Score :' , f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE : Embedding +Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.1436, Train error: 0.0308\n",
      "Epoch: 2, Loss: 0.0837, Train error: 0.0385\n",
      "Epoch: 3, Loss: 0.0532, Train error: 0.0231\n",
      "Epoch: 4, Loss: 0.0735, Train error: 0.0231\n",
      "Epoch: 5, Loss: 0.0759, Train error: 0.0308\n",
      "Epoch: 6, Loss: 0.0483, Train error: 0.0231\n",
      "Epoch: 7, Loss: 0.0893, Train error: 0.0308\n",
      "Epoch: 8, Loss: 0.0431, Train error: 0.0154\n",
      "Epoch: 9, Loss: 0.0489, Train error: 0.0308\n",
      "Epoch: 10, Loss: 0.0627, Train error: 0.0231\n",
      "Epoch: 11, Loss: 0.0671, Train error: 0.0231\n",
      "Epoch: 12, Loss: 0.0492, Train error: 0.0231\n",
      "Epoch: 13, Loss: 0.0633, Train error: 0.0308\n",
      "Epoch: 14, Loss: 0.0676, Train error: 0.0308\n",
      "Epoch: 15, Loss: 0.0587, Train error: 0.0154\n",
      "Epoch: 16, Loss: 0.0773, Train error: 0.0308\n",
      "Epoch: 17, Loss: 0.0465, Train error: 0.0231\n",
      "Epoch: 18, Loss: 0.0600, Train error: 0.0231\n",
      "Epoch: 19, Loss: 0.0509, Train error: 0.0231\n"
     ]
    }
   ],
   "source": [
    "model = Emb_mean()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 1.1652, Test error: 0.2667\n",
      "Accuracy : 0.7333333333333333\n",
      "Precision : 0.6666666666666666\n",
      "Recall : 0.9333333333333333\n",
      "F1 Score : 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE : Embedding +max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6581, Train error: 0.3385\n",
      "Epoch: 2, Loss: 0.2305, Train error: 0.0923\n",
      "Epoch: 3, Loss: 0.2007, Train error: 0.0615\n",
      "Epoch: 4, Loss: 0.1821, Train error: 0.0462\n",
      "Epoch: 5, Loss: 0.1352, Train error: 0.0538\n",
      "Epoch: 6, Loss: 0.0986, Train error: 0.0462\n",
      "Epoch: 7, Loss: 0.0684, Train error: 0.0308\n",
      "Epoch: 8, Loss: 0.0664, Train error: 0.0385\n",
      "Epoch: 9, Loss: 0.0709, Train error: 0.0308\n",
      "Epoch: 10, Loss: 0.0778, Train error: 0.0308\n",
      "Epoch: 11, Loss: 0.1193, Train error: 0.0308\n",
      "Epoch: 12, Loss: 0.0477, Train error: 0.0077\n",
      "Epoch: 13, Loss: 0.0325, Train error: 0.0077\n",
      "Epoch: 14, Loss: 0.0419, Train error: 0.0154\n",
      "Epoch: 15, Loss: 0.0643, Train error: 0.0154\n",
      "Epoch: 16, Loss: 0.0437, Train error: 0.0154\n",
      "Epoch: 17, Loss: 0.0563, Train error: 0.0308\n",
      "Epoch: 18, Loss: 0.0398, Train error: 0.0077\n",
      "Epoch: 19, Loss: 0.0943, Train error: 0.0462\n"
     ]
    }
   ],
   "source": [
    "model = Emb_max()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 3.9925, Test error: 0.5000\n",
      "Accuracy : 0.5\n",
      "Precision : 0.5\n",
      "Recall : 1.0\n",
      "F1 Score : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.2321, Train error: 0.0923\n",
      "Epoch: 2, Loss: 0.0520, Train error: 0.0385\n",
      "Epoch: 3, Loss: 0.0681, Train error: 0.0154\n",
      "Epoch: 4, Loss: 0.0791, Train error: 0.0154\n",
      "Epoch: 5, Loss: 0.0778, Train error: 0.0231\n",
      "Epoch: 6, Loss: 0.0512, Train error: 0.0154\n",
      "Epoch: 7, Loss: 0.2161, Train error: 0.0385\n",
      "Epoch: 8, Loss: 0.0871, Train error: 0.0308\n",
      "Epoch: 9, Loss: 0.0827, Train error: 0.0231\n",
      "Epoch: 10, Loss: 0.0658, Train error: 0.0308\n",
      "Epoch: 11, Loss: 0.0317, Train error: 0.0154\n",
      "Epoch: 12, Loss: 0.0502, Train error: 0.0231\n",
      "Epoch: 13, Loss: 0.0641, Train error: 0.0308\n",
      "Epoch: 14, Loss: 0.0456, Train error: 0.0154\n",
      "Epoch: 15, Loss: 0.0716, Train error: 0.0385\n",
      "Epoch: 16, Loss: 0.0266, Train error: 0.0077\n",
      "Epoch: 17, Loss: 0.0201, Train error: 0.0077\n",
      "Epoch: 18, Loss: 0.0824, Train error: 0.0154\n",
      "Epoch: 19, Loss: 0.0498, Train error: 0.0154\n"
     ]
    }
   ],
   "source": [
    "model = Attention(hidden_size=512, dropout=0.5)\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 1.6763, Test error: 0.4167\n",
      "Accuracy : 0.5833333333333334\n",
      "Precision : 0.5510204081632653\n",
      "Recall : 0.9\n",
      "F1 Score : 0.6835443037974683\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.1443, Train error: 0.0692\n",
      "Epoch: 2, Loss: 0.1035, Train error: 0.0462\n",
      "Epoch: 3, Loss: 0.0730, Train error: 0.0231\n",
      "Epoch: 4, Loss: 0.0980, Train error: 0.0231\n",
      "Epoch: 5, Loss: 0.0736, Train error: 0.0154\n",
      "Epoch: 6, Loss: 0.0417, Train error: 0.0231\n",
      "Epoch: 7, Loss: 0.1275, Train error: 0.0385\n",
      "Epoch: 8, Loss: 0.0563, Train error: 0.0231\n",
      "Epoch: 9, Loss: 0.0674, Train error: 0.0231\n",
      "Epoch: 10, Loss: 0.0765, Train error: 0.0308\n",
      "Epoch: 11, Loss: 0.0749, Train error: 0.0154\n",
      "Epoch: 12, Loss: 0.0664, Train error: 0.0154\n",
      "Epoch: 13, Loss: 0.0511, Train error: 0.0077\n",
      "Epoch: 14, Loss: 0.0610, Train error: 0.0308\n",
      "Epoch: 15, Loss: 0.0507, Train error: 0.0308\n",
      "Epoch: 16, Loss: 0.0329, Train error: 0.0154\n",
      "Epoch: 17, Loss: 0.0691, Train error: 0.0231\n",
      "Epoch: 18, Loss: 0.0567, Train error: 0.0154\n",
      "Epoch: 19, Loss: 0.0515, Train error: 0.0231\n"
     ]
    }
   ],
   "source": [
    "model = GatedAttention(hidden_size=512, dropout=0.1)\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 0.5719, Test error: 0.2000\n",
      "Accuracy : 0.8\n",
      "Precision : 0.7647058823529411\n",
      "Recall : 0.8666666666666667\n",
      "F1 Score : 0.8125\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VarMIL(embed_size= 1024, hidden_size=500,separate_attn=False, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.2162, Train error: 0.1154\n",
      "Epoch: 2, Loss: 0.0812, Train error: 0.0385\n",
      "Epoch: 3, Loss: 0.1095, Train error: 0.0308\n",
      "Epoch: 4, Loss: 0.0740, Train error: 0.0231\n",
      "Epoch: 5, Loss: 0.0865, Train error: 0.0231\n",
      "Epoch: 6, Loss: 0.1092, Train error: 0.0385\n",
      "Epoch: 7, Loss: 0.0683, Train error: 0.0231\n",
      "Epoch: 8, Loss: 0.1585, Train error: 0.0308\n",
      "Epoch: 9, Loss: 0.0927, Train error: 0.0308\n",
      "Epoch: 10, Loss: 0.1347, Train error: 0.0231\n",
      "Epoch: 11, Loss: 0.0467, Train error: 0.0231\n",
      "Epoch: 12, Loss: 0.0799, Train error: 0.0308\n",
      "Epoch: 13, Loss: 0.1070, Train error: 0.0231\n",
      "Epoch: 14, Loss: 0.1063, Train error: 0.0385\n",
      "Epoch: 15, Loss: 0.0234, Train error: 0.0000\n",
      "Epoch: 16, Loss: 0.0382, Train error: 0.0231\n",
      "Epoch: 17, Loss: 0.0795, Train error: 0.0385\n",
      "Epoch: 18, Loss: 0.0994, Train error: 0.0308\n",
      "Epoch: 19, Loss: 0.0505, Train error: 0.0308\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 4.3909, Test error: 0.5000\n",
      "Accuracy : 0.5\n",
      "Precision : 0.5\n",
      "Recall : 1.0\n",
      "F1 Score : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.2497, Train error: 0.0769\n",
      "Epoch: 2, Loss: 0.2194, Train error: 0.0385\n",
      "Epoch: 3, Loss: 0.4246, Train error: 0.0462\n",
      "Epoch: 4, Loss: 0.4142, Train error: 0.0538\n",
      "Epoch: 5, Loss: 0.1606, Train error: 0.0308\n",
      "Epoch: 6, Loss: 0.0800, Train error: 0.0231\n",
      "Epoch: 7, Loss: 0.3839, Train error: 0.0385\n",
      "Epoch: 8, Loss: 0.1210, Train error: 0.0154\n",
      "Epoch: 9, Loss: 0.1895, Train error: 0.0231\n",
      "Epoch: 10, Loss: 0.7841, Train error: 0.0462\n",
      "Epoch: 11, Loss: 0.2468, Train error: 0.0308\n",
      "Epoch: 12, Loss: 0.2805, Train error: 0.0308\n",
      "Epoch: 13, Loss: 0.2389, Train error: 0.0308\n",
      "Epoch: 14, Loss: 0.6565, Train error: 0.0154\n",
      "Epoch: 15, Loss: 0.2073, Train error: 0.0308\n",
      "Epoch: 16, Loss: 0.3936, Train error: 0.0231\n",
      "Epoch: 17, Loss: 0.5886, Train error: 0.0462\n",
      "Epoch: 18, Loss: 0.3669, Train error: 0.0462\n",
      "Epoch: 19, Loss: 0.4109, Train error: 0.0385\n"
     ]
    }
   ],
   "source": [
    "model = CLAM_SB()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch, model, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 0.4810, Test error: 0.2667\n",
      "Accuracy : 0.7333333333333333\n",
      "Precision : 0.6842105263157895\n",
      "Recall : 0.8666666666666667\n",
      "F1 Score : 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
