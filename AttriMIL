import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data

class AttriMIL(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, attr_dim, num_layers=4, dropout=0.5):
        super(AttriMIL, self).__init__()

        self.feature_extraction_layers = nn.ModuleList()
        self.feature_extraction_layers.append(GCNConv(in_channels, hidden_channels))

        for _ in range(num_layers - 2):
            self.feature_extraction_layers.append(GCNConv(hidden_channels, hidden_channels))

        self.feature_extraction_layers.append(GCNConv(hidden_channels, out_channels))

        self.dropout = dropout
        self.attribute_attention_layer = nn.Linear(out_channels + attr_dim, 1)  # Combine features and attributes

    def forward(self, node_features, edge_index, attributes):
        x = node_features
        for i, conv in enumerate(self.feature_extraction_layers):
            x = conv(x, edge_index)
            if i < len(self.feature_extraction_layers) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)

        # Concatenate node features with attributes
        combined_features = torch.cat([x, attributes], dim=1)

        # Compute attention weights
        attention_weights = torch.softmax(self.attribute_attention_layer(combined_features), dim=0)

        # Compute global feature as a weighted sum of node features
        global_feature = torch.sum(attention_weights * x, dim=0, keepdim=True)

        return global_feature, attention_weights

# Graph construction helper function
def construct_graph(node_features, adjacency_matrix):
    edge_index = torch.nonzero(adjacency_matrix, as_tuple=False).T
    return Data(x=node_features, edge_index=edge_index)

# Example graph givem
if __name__ == "__main__":
    # Sample node features and adjacency matrix
    num_nodes = 10
    feature_dim = 1024
    attr_dim = 128  # Dimension of attribute vectors

    node_features = torch.rand((num_nodes, feature_dim))
    attributes = torch.rand((num_nodes, attr_dim))  # Randomly generated attributes
    adjacency_matrix = torch.eye(num_nodes) + torch.rand((num_nodes, num_nodes)) > 0.5
    adjacency_matrix = adjacency_matrix.int()

    graph_data = construct_graph(node_features, adjacency_matrix)

    model = AttriMIL(in_channels=feature_dim, hidden_channels=512, out_channels=128, attr_dim=attr_dim, num_layers=4, dropout=0.5)

    global_feature, attention_weights = model(graph_data.x, graph_data.edge_index, attributes)
    print("Global Feature:", global_feature)
    print("Attention Weights:", attention_weights)
